### VMware

- 빅데이터
  - 빅데이터 플랫폼 구축
    - 계정 :root 
    - pass : bitdata
    - VMware설치
    - 네트워크를 위한 설정 파일 복사
      - vmnercfg.exe - player버전과 vmnetcfg.exe를 복사한 workstation pro버전이 동일 해야한다
    - CentOS설치
    - 머신복제
      - copy(파워off후 작업)
      - `I copied it`   선택 후 진행
      - root(관리자)계정으로 선 접속 후 hadoop으로 진행
    - 하둡머신 클러스터링
      - 4대를 연결 : 머신1에서 ssh통신을 이용하여 원격접속
        - `ssh "연결할 머신의 아이피" `
          - ssh(Secure shell)
            - 서버와 클라이언트간의 텍스트 기반으로 통신 , 암호화해서 통신하기위한 프로토콜
        - 호스트명 변경 : `hostnamectl set-hostname "변경할 name"` 
      - 현재 실행중인 프로그램 확인 : `system list-nuit --type=service`     종료 :`ctrl + c`
      - 방화벽해제 : `systemctl stop firewalld`
      - 방화벽확인 : `systemctl status firewalld`
      - 서비스 비활성화 : `system disable firewalld`
      - 도메인 등록 
        - ssh통신을 하기위해 hadoop01에서 나머지 머신을 접근
        - ip로 접근하기 불편하므로 호스트명을 변경해서 작업
        - /etc/hosts 파일 수정 >> 기존내용삭제 후  `ip주소 "변경할 도메인명"` 작성
        - 네트워크 리스타트 : /etc/init.d/network restart
        - `ssh "도메인명 "`
        - 호스트 파일을 다른 머신으로 복사
          - `scp /etc/hosts root@"도메인명":/etc/hosts`
      - 네트워크 restart
  - IP변경시 해야될 작업 
    - /etc/hosts파일 변경  --- root계정
    - 모든 머신 copy --- root계정
      - scp /etc/hosts root@hadoop02:/etc/hosts
    - /etc/init.d/network restart  (모든 머신) --- root계정
    - /home/hadoop/hadoop-1.2.1/conf의 core-site.xml, mapred-site.xml, hdfs-site.xml파일의 주소변경 및 모든 머신에 복사 
      - hadoop계정
    - sts프로젝트 cong폴더의 모든 설정파일의 주소변경
  - 명령어
    - scp : 로컬  > 원격지 복사
    - cp : 로컬 > 로컬 복사
  - 디렉토리 구조
    - /home : 사용자 계정의 홈디렉토리
    - /boot : 부팅에 필요한 각종 설정파일이 위치하는곳
    - /root : root계정의 홈디렉토리
    - /bin : 리눅스에서 사용할수 있는 shell명령어가 위치하는곳
    - /sbin : 시스템관리를 위한  명령어가 위치하는곳
    - /etc : 시스템관리를 위한 설정파일이 위치하는 디렉토리(사용자정보, 파일시스템정보, 네트워크정보,.......)
    - /tmp : 시스템이 작업 중 사용하는 임시 폴더
    - /var : tmp와 유사 보통 로그 파일이 위치
    - /lib : 공통 라이브러리 파일이 저장되는 위치
    - /dev : 장치가 위치하는 디렉토리  - 리눅스는 모든 장치를 파일로 인식
    - /usr : 윈도우의 program files와 동일
    - /passwd : 사용자 계정 정보의 저장 장소
    - /rpm -Uvh 
      - u : 이전 버전이 있으면 업그레이드
      - v : 성치되는 과정을 보여주기
      - h : 설치과정에 #을 추가하기

----

### Hadoop

- hadoop 설치과정
  - jdk설치
  - hadoop설치
    - 커널버전
      - 1.x
      - 2.x
      - 3.x
  - ssh프로토콜로 암호통신을 할 수 있도록 설정하기
    - 하둡 내부에서 ssh통신을 하기 때문에 통신 할 수 있도록 설정
    - 암호키를 생성하고 공용키만 각 머신에 배포
  - hadoop설정
    - conf폴더의 설정파일을 셋팅
    - 네임노드 초기화
    - hadoop 실행
      - start -all.sh
    - 실행 후 데몬 확인
      - jps
  - hadoop 프로그래밍
    - hdfs
    - mapreduce
      - 데이터를 분류하는역활
      - mapper클래스를 상속한다,
        - mapper로 전달될 input데이터의 key, value타입 mapper의 실행결과로 출력될 output데이터의 key와 value타입을 정의
        - map메소드를 오버라이딩해서 map작업을 어떤 방식으로 처리할 것 인지 내용을 구현
          - 입력된 값을 분석하기 위한 메소드 
          - 입력된 데이터에 조건을 적용하여 원하는 데이터만 추출하기 위한 반복작업 수행
        - map메소드의  매개변수
          - 입력데이터 키, 입력값, context
          - 맵리듀스 작업을 수행하며 맵메소드의 실행결과를 프레임워크 내부에서 처리하는 다른 컴포넌트로 전달
          - 출력데이터를 기록하고 shuffle단으로 넘기고 리듀서로 내보내는 작업을 내부에서 처리할 객체 프레임워크 내부에서 기본작업을 처리하는 객체
          - 내부에서 머신들끼리 통신할때 필요한 여러가지 정보를 갖고 있는 객체
    - Reducer
      - 데이터를 집계하는 역할
      - Reducer클래스를 상속
        - reducer로 전달되는 input데이터의 key,value타입 , Reducer의 실행결과로 출력될 output데이터의  key,value타입을 명시
        - reduce메소드를 오버라이딩
          - key,value,Context객체가 전달
          - Mapper와 동일
          - reducer로 전달되는 value의 타입이 Iterable`<IntWritable>`  Iterable 즉, 입력값들이 Iterable의 형태로 전달
            -  {1,1,1,1,1,1,1,.....} 값에서 한 개의 value타입은 IntWritable이지만 여러 개가 전달되므로 반복작업을 수행해야 하고 여러 개가 전달되는 것을 Iterable의 형태로 전달받는다.
    - Driver
      - 맵리듀스를 실행하기 위한 작업을 처리하는 클래스
      -  맵리듀스를 처리하기 위한  job을 생성
      - 실제 job을 처리하기 위한 클래스가 어떤 클래스인지 등록
        - Mapper, Reducer, Driver클래스가 어떤 클래스인지 우리가 작성한 클래스를 등록
      - HDFS에서 읽고 쓸 input데이터와 output데이터의 포맷을 정의
        - 텍스트 파일의 형태로 input/output형태로 처리
      - 리듀서의 출력데이터에 대한 키와 value타입을 정의
      - hdfs에 저장된 파일을 읽고 쓸 수 있도록 path를 정의
      - job실행
    - customizing
    
    - 사용자정의 옵션 활용
      - Mapper 
        - 환경설정 정보에서 사용자가 입력한 옵션정보를 읽기 위해서 setup메소드를 오버라이딩해서 처리
        - map메소드 내부에서 값에 따라 다르게 동작할 수 있도록 구현
      - Reducer
        - 기존과 동일
      - Driver
        - 사용자가  -D옵션을 이용해서 입력한 옵션값을 프로그램 안에서 사용할 수 있도록 즉 ,Mapper가 사용할수 있도록 전달
      - Configured(클래스)와 Tool(인터페이스)을 상속
        - configured는 환경설정 정보를 활용해야 하므로
        - tool은 사용자 정의 옵션을 사용하기 위해서
        - 사용자가 입력한 옵션과 input/output 경로가 입력된 기존 명령형매개변수를 구분해서 전달해야 하므로
      - run메소드를 오버라이딩
        - run메소드 내부에서 Driver에서 구현했던 모든 코드를 구현
        - GenericOptionParser를 이용해서 사용자가 입력한 옵션과 일반옵션을 분리해서 환경설정 정보에 등록되도록 처리
          - 작업이 완료시 mapper 환경 설정정보에서 값을 꺼내서 사용할수있다.
      - main메소드에서 run을 실행되도록 호출
        - run은 직접 호출하지않고 toolTunner클래스 실행될 메소드로 run을 등록해야 한다.
        - 스케줄러에 의해 호출된다.
    
    - Multiple outputs
      - 한 개의 입력 데이터를 이용해서 여러 개의 output을 만들고 싶은경우 활용
        - Mapper 
          - GenericOptionParsar작업과 동일하게 map메소드를 구성하고 구분할 수 있도록 key의 각 상황별 문자추가
        - Reducer
          - Mapper에서 넘겨준 데이터에서 구분자를 기준으로 분리해서 합산
          - 개별 output이 생성될 수 있도록 처리
            - setup
              - reducer객체가 처음 실행 될때 한번 호출 되는 메소드pl
              - multipleoutputs객체 생성
            - reduce
              - 위와 동일
              - 각 상황별로 write를 호출해서 출력 될 수 있도록 처리
              - up,down, equal 작업(stock multi예제)
            - cleanUp
              - reducer의 작업이 종료될때 한번 호출 되는 메소드
              - multipleoutputs객체를 반드시 해제
        - Driver
          - multipleoutputs로 출력될 경로를 path에 설정
          - prefix로 구분문자열을 정의
      - 보조정렬
        - 기존의 맵리듀스에서 정렬되는 기본 키 방식과 다르게 정렬 기준을 추가해서 정렬
        - 보조정렬은 키 값을 그룹핑하고 그룹핑된 레코드에 순서를 부여하면서 정렬하는 방식
        - 사용자 정의 키 작성
          - 복합키 구현
          - 클래스가 사용자정의 키
          - 정렬할 기준을 컬럼으로 갖고 있는 객체
          - 맵리듀스 프레임워크 내부에서 key/value는 네트워크에서 주고 받는 값이므로 writable타입 이어야 한다.
            - writable타입
              - 하둡내부에서 네트원크 전송을 위해 가능하도록 만들어진타입
              - 주고받을 키와 value의 데이터타입이 모두 writable의 하위클래스
          - writableComparavle상속
          - 비교기준을 멤버변수로 정의
          - 데이터를 쓰고 읽는 작업을 처리하기 위해 메소드 오버라이딩
            - 네트워크를 통해서 key가 전송되므로 사용자정의key가 네트워크로 전송될수 있도록 보내고 받는 작업을 처리, 이는 하둡의 맵리듀스 프레임워크 내부에서 지원하는 기능을 활용(writableUtils)
            - readFields오버라이딩
              - 데이터를 읽기 (역직렬화)
            - wirte오버라이딩
              - 데이터를 쓰기(직렬화)
            - compareTO오버라이딩
              - 순서를 정하기 위해서 커스텀 키를 비교하는 메소드 
          - Mapper작성하기
            - 사용자키가 outputkey로 출력될 수 있도록 정의
          - Partitioner를 정의하기
            - Reduce태스크에 분배할 수 있는  Partitioner를 정의
            - 같은 키를 갖고 있는 mapper의 출력데이터를 같은 리듀스 태스크로 보내기 위해서 해시코드를 이용하여  계산
            - Partitioner상속
              - Partitioner의 역활을 하기 위해서 상속
              - 프레임워크 내부에서 호출될 수 있도록 Partitioner를 상속
              - year를 기준으로 같은 year를 갖고 있는 데이터를 같은 리듀서에서 작업이 진행되도록 분배
              - 같은 것끼리 메모리버퍼에 쌓았다가 한꺼번에 전송
          - 그룹키
            - Reducer태스크로 보내기 전에 같은 그룹으로 그룹핑을 할 수 있도록 객체를 정의
              - 그룹키 비교기
              - ex) air데이터에서 같은 년도별로 데이터를 분류
          - 그룹키에서 같은 그룹으로 데이터 내부에서 두 번쨰 기준을 적용하여 비교 할 수 있도록 객체를 정의
            - 기준이 많으면 모두 비교 할 수 있도록  구현
            - 복합키를 기준으로 데이터를 정렬하기 위해 사용하는 객체
            - 복합키 비교기(복합키에 정의한 모든 기준을 비교 검토할 수 있도록 처리)
          - 리듀서
          - 드라이버
  - hadoop eco system 설치 후 테스트
    - flume
    - sqoop
    - hive
    - pig
    - mahout
  
  
